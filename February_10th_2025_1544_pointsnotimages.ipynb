{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlQQmcGmGu9Xm2vZpVrvE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DannyinDelft/INR/blob/main/February_10th_2025_1544_pointsnotimages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWpcZwReVGdh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Point-based Training and Testing for Custom SIREN Model with Georeferencing and Distinct Outputs\n",
        "\"\"\"\n",
        "!pip install rasterio geopandas torch torchmetrics\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.transform import from_bounds\n",
        "from google.colab import drive\n",
        "import re\n",
        "from torchmetrics.image import PeakSignalNoiseRatio\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Running on device: {device}\")\n",
        "\n",
        "# ðŸ”¹ Fourier Encoding for High-Frequency Details\n",
        "class FourierEncoding(nn.Module):\n",
        "    def __init__(self, input_dim, mapping_size=128, scale=40.0):\n",
        "        super().__init__()\n",
        "        self.B = torch.randn((input_dim, mapping_size)) * scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_proj = 2 * np.pi * x @ self.B.to(x.device)\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "# ðŸ”¹ SIREN Layer\n",
        "class SirenLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, omega=30.0, is_first=False):\n",
        "        super(SirenLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_channels, out_channels)\n",
        "        self.omega = omega\n",
        "        self.init_weights(is_first)\n",
        "\n",
        "    def init_weights(self, is_first):\n",
        "        with torch.no_grad():\n",
        "            bound = 1 / self.linear.in_features if is_first else np.sqrt(6 / self.linear.in_features) / self.omega\n",
        "            nn.init.uniform_(self.linear.weight, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sin(self.omega * self.linear(x))\n",
        "\n",
        "# ðŸ”¹ Total Variation Loss for Smoother Images\n",
        "def total_variation_loss(img):\n",
        "    if img.ndim == 1:\n",
        "        return torch.tensor(0.0, device=img.device)\n",
        "\n",
        "    img = img.view(-1, 1, int(np.sqrt(img.shape[0])), int(np.sqrt(img.shape[0])))\n",
        "    dx = torch.abs(img[:, :, :-1, :] - img[:, :, 1:, :]).mean()\n",
        "    dy = torch.abs(img[:, :, :, :-1] - img[:, :, :, 1:]).mean()\n",
        "    return dx + dy\n",
        "\n",
        "# ðŸ”¹ Custom Loss Function (MSE + TV Loss)\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.001):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss_mse = self.mse(outputs, targets)\n",
        "        loss_tv = total_variation_loss(outputs)\n",
        "        return loss_mse + self.alpha * loss_tv\n",
        "\n",
        "# ðŸ”¹ SIREN Model (Fixed Input-Output Dimension Issue)\n",
        "class CustomSirenModel(nn.Module):\n",
        "    def __init__(self, input_dim=2, fourier_dim=256, site_embedding_dim=128, hidden_features=512, hidden_layers=8, out_features=1):\n",
        "        super(CustomSirenModel, self).__init__()\n",
        "        self.fourier = FourierEncoding(input_dim, mapping_size=fourier_dim)\n",
        "        self.site_embeddings = nn.Embedding(20, site_embedding_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([SirenLayer(fourier_dim * 2 + site_embedding_dim, hidden_features, is_first=True)])\n",
        "        self.layers.extend([SirenLayer(hidden_features, hidden_features) for _ in range(hidden_layers)])\n",
        "        self.final_layer = nn.Linear(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x, site_id):\n",
        "        fourier_encoded = self.fourier(x)\n",
        "        site_embed = self.site_embeddings(site_id).squeeze(0)\n",
        "        site_embed = site_embed.unsqueeze(0).expand(x.size(0), -1)\n",
        "\n",
        "        x = torch.cat([fourier_encoded, site_embed], dim=-1)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return self.final_layer(x)\n",
        "\n",
        "# ðŸ”¹ Sample Ground Truth Pixel Values\n",
        "def sample_ground_truth(raster_path, coords, raster_crs, raster_bounds):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        if raster_crs != src.crs:\n",
        "            coords = coords.to_crs(src.crs)\n",
        "\n",
        "        values = []\n",
        "        valid_coords = []\n",
        "        for point in coords.geometry:\n",
        "            x, y = point.x, point.y\n",
        "            if raster_bounds[0] <= x <= raster_bounds[2] and raster_bounds[1] <= y <= raster_bounds[3]:\n",
        "                try:\n",
        "                    row, col = src.index(x, y)\n",
        "                    val = src.read(1)[row, col]\n",
        "                    if not np.isnan(val):\n",
        "                        values.append(val)\n",
        "                        valid_coords.append((x, y))\n",
        "                except Exception:\n",
        "                    continue\n",
        "        return torch.tensor(values, dtype=torch.float32).to(device), valid_coords\n",
        "\n",
        "# ðŸ”¹ Training Function\n",
        "def train(model, train_loader, raster_loader, epochs=500):\n",
        "    model.train()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-6)\n",
        "    loss_fn = CustomLoss(alpha=0.001)\n",
        "    psnr_metric = PeakSignalNoiseRatio()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_psnr = 0\n",
        "        for site_id in sorted(train_loader.keys()):\n",
        "            coords, file_name = train_loader[site_id]\n",
        "            if site_id not in raster_loader:\n",
        "                continue\n",
        "\n",
        "            raster_path, raster_crs, raster_bounds, _ = raster_loader[site_id]\n",
        "            targets, valid_coords = sample_ground_truth(raster_path, coords, raster_crs, raster_bounds)\n",
        "\n",
        "            if len(valid_coords) == 0:\n",
        "                continue\n",
        "\n",
        "            coords_tensor = torch.tensor(valid_coords, dtype=torch.float32).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(coords_tensor, torch.tensor([site_id], dtype=torch.long).to(device)).squeeze()\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            total_psnr += psnr_metric(outputs, targets).item()\n",
        "\n",
        "        avg_psnr = total_psnr / len(train_loader)\n",
        "        print(f\"ðŸ”¥ Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.6f}, PSNR: {avg_psnr:.2f}\")\n",
        "\n",
        "# ðŸ”¹ Main Function (Corrected Format)\n",
        "def main():\n",
        "    model = CustomSirenModel().to(device)\n",
        "\n",
        "    train_input_path = \"/content/drive/My Drive/Thesis_imagery/Ecostress/1000mpatches/Rastertopoint/Training_input\"\n",
        "    train_gt_path = \"/content/drive/My Drive/Thesis_imagery/Ecostress/1000mpatches/Rastertopoint/Training_ground_truth\"\n",
        "    test_input_path = \"/content/drive/My Drive/Thesis_imagery/Ecostress/1000mpatches/Rastertopoint/Testing_input\"\n",
        "    output_dir = \"/content/drive/My Drive/Thesis_imagery/Ecostress/1000mpatches/Rastertopoint/Testing_output\"\n",
        "\n",
        "    train(model, point_data_loader(train_input_path, \"EPSG:25832\"), raster_data_loader(train_gt_path), epochs=500)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "inqVtd9bVYAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eef5dda-a10f-42c4-838d-daafb922493b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.17.0)\n",
            "Mounted at /content/drive\n",
            "Running on device: cpu\n",
            "ðŸ”¥ Epoch [1/500], Loss: 35.631991, PSNR: -1.26\n",
            "ðŸ”¥ Epoch [2/500], Loss: 11.631541, PSNR: 2.25\n",
            "ðŸ”¥ Epoch [3/500], Loss: 6.158193, PSNR: 5.04\n",
            "ðŸ”¥ Epoch [4/500], Loss: 3.326389, PSNR: 7.73\n",
            "ðŸ”¥ Epoch [5/500], Loss: 2.401338, PSNR: 9.07\n",
            "ðŸ”¥ Epoch [6/500], Loss: 2.095396, PSNR: 9.67\n",
            "ðŸ”¥ Epoch [7/500], Loss: 1.787045, PSNR: 10.37\n",
            "ðŸ”¥ Epoch [8/500], Loss: 1.624843, PSNR: 10.79\n",
            "ðŸ”¥ Epoch [9/500], Loss: 1.475496, PSNR: 11.18\n",
            "ðŸ”¥ Epoch [10/500], Loss: 1.316284, PSNR: 11.71\n",
            "ðŸ”¥ Epoch [11/500], Loss: 1.232681, PSNR: 11.98\n",
            "ðŸ”¥ Epoch [12/500], Loss: 1.183088, PSNR: 12.16\n",
            "ðŸ”¥ Epoch [13/500], Loss: 1.063981, PSNR: 12.62\n",
            "ðŸ”¥ Epoch [14/500], Loss: 0.999276, PSNR: 12.89\n",
            "ðŸ”¥ Epoch [15/500], Loss: 0.905716, PSNR: 13.32\n",
            "ðŸ”¥ Epoch [16/500], Loss: 0.854789, PSNR: 13.55\n",
            "ðŸ”¥ Epoch [17/500], Loss: 0.790212, PSNR: 13.91\n",
            "ðŸ”¥ Epoch [18/500], Loss: 0.733145, PSNR: 14.22\n",
            "ðŸ”¥ Epoch [19/500], Loss: 0.699699, PSNR: 14.43\n",
            "ðŸ”¥ Epoch [20/500], Loss: 0.613211, PSNR: 15.00\n",
            "ðŸ”¥ Epoch [21/500], Loss: 0.582366, PSNR: 15.25\n",
            "ðŸ”¥ Epoch [22/500], Loss: 0.549289, PSNR: 15.49\n",
            "ðŸ”¥ Epoch [23/500], Loss: 0.491609, PSNR: 15.97\n",
            "ðŸ”¥ Epoch [24/500], Loss: 0.462911, PSNR: 16.23\n",
            "ðŸ”¥ Epoch [25/500], Loss: 0.420768, PSNR: 16.65\n",
            "ðŸ”¥ Epoch [26/500], Loss: 0.368318, PSNR: 17.22\n",
            "ðŸ”¥ Epoch [27/500], Loss: 0.355014, PSNR: 17.37\n",
            "ðŸ”¥ Epoch [28/500], Loss: 0.307177, PSNR: 18.02\n",
            "ðŸ”¥ Epoch [29/500], Loss: 0.292419, PSNR: 18.22\n",
            "ðŸ”¥ Epoch [30/500], Loss: 0.278690, PSNR: 18.44\n",
            "ðŸ”¥ Epoch [31/500], Loss: 0.237327, PSNR: 19.14\n",
            "ðŸ”¥ Epoch [32/500], Loss: 0.216530, PSNR: 19.53\n",
            "ðŸ”¥ Epoch [33/500], Loss: 0.209165, PSNR: 19.70\n",
            "ðŸ”¥ Epoch [34/500], Loss: 0.182050, PSNR: 20.28\n",
            "ðŸ”¥ Epoch [35/500], Loss: 0.163404, PSNR: 20.76\n",
            "ðŸ”¥ Epoch [36/500], Loss: 0.153009, PSNR: 21.03\n",
            "ðŸ”¥ Epoch [37/500], Loss: 0.138603, PSNR: 21.47\n",
            "ðŸ”¥ Epoch [38/500], Loss: 0.121381, PSNR: 22.04\n",
            "ðŸ”¥ Epoch [39/500], Loss: 0.104542, PSNR: 22.70\n",
            "ðŸ”¥ Epoch [40/500], Loss: 0.097737, PSNR: 22.98\n",
            "ðŸ”¥ Epoch [41/500], Loss: 0.090361, PSNR: 23.33\n",
            "ðŸ”¥ Epoch [42/500], Loss: 0.079977, PSNR: 23.86\n",
            "ðŸ”¥ Epoch [43/500], Loss: 0.075252, PSNR: 24.13\n",
            "ðŸ”¥ Epoch [44/500], Loss: 0.069913, PSNR: 24.44\n",
            "ðŸ”¥ Epoch [45/500], Loss: 0.062010, PSNR: 24.98\n",
            "ðŸ”¥ Epoch [46/500], Loss: 0.058319, PSNR: 25.24\n",
            "ðŸ”¥ Epoch [47/500], Loss: 0.050859, PSNR: 25.84\n",
            "ðŸ”¥ Epoch [48/500], Loss: 0.047973, PSNR: 26.08\n",
            "ðŸ”¥ Epoch [49/500], Loss: 0.042818, PSNR: 26.58\n",
            "ðŸ”¥ Epoch [50/500], Loss: 0.038243, PSNR: 27.10\n",
            "ðŸ”¥ Epoch [51/500], Loss: 0.036057, PSNR: 27.34\n",
            "ðŸ”¥ Epoch [52/500], Loss: 0.032234, PSNR: 27.82\n",
            "ðŸ”¥ Epoch [53/500], Loss: 0.029266, PSNR: 28.25\n",
            "ðŸ”¥ Epoch [54/500], Loss: 0.027331, PSNR: 28.52\n",
            "ðŸ”¥ Epoch [55/500], Loss: 0.025362, PSNR: 28.89\n",
            "ðŸ”¥ Epoch [56/500], Loss: 0.023636, PSNR: 29.21\n",
            "ðŸ”¥ Epoch [57/500], Loss: 0.022457, PSNR: 29.42\n",
            "ðŸ”¥ Epoch [58/500], Loss: 0.019820, PSNR: 29.98\n",
            "ðŸ”¥ Epoch [59/500], Loss: 0.018544, PSNR: 30.26\n",
            "ðŸ”¥ Epoch [60/500], Loss: 0.017530, PSNR: 30.55\n",
            "ðŸ”¥ Epoch [61/500], Loss: 0.016629, PSNR: 30.74\n",
            "ðŸ”¥ Epoch [62/500], Loss: 0.016037, PSNR: 30.92\n",
            "ðŸ”¥ Epoch [63/500], Loss: 0.014550, PSNR: 31.36\n",
            "ðŸ”¥ Epoch [64/500], Loss: 0.013562, PSNR: 31.66\n",
            "ðŸ”¥ Epoch [65/500], Loss: 0.013675, PSNR: 31.64\n",
            "ðŸ”¥ Epoch [66/500], Loss: 0.012608, PSNR: 32.03\n",
            "ðŸ”¥ Epoch [67/500], Loss: 0.012361, PSNR: 32.10\n",
            "ðŸ”¥ Epoch [68/500], Loss: 0.011037, PSNR: 32.62\n",
            "ðŸ”¥ Epoch [69/500], Loss: 0.011215, PSNR: 32.56\n",
            "ðŸ”¥ Epoch [70/500], Loss: 0.010694, PSNR: 32.76\n",
            "ðŸ”¥ Epoch [71/500], Loss: 0.010596, PSNR: 32.80\n",
            "ðŸ”¥ Epoch [72/500], Loss: 0.010350, PSNR: 32.92\n",
            "ðŸ”¥ Epoch [73/500], Loss: 0.009941, PSNR: 33.10\n",
            "ðŸ”¥ Epoch [74/500], Loss: 0.009402, PSNR: 33.44\n",
            "ðŸ”¥ Epoch [75/500], Loss: 0.009063, PSNR: 33.52\n",
            "ðŸ”¥ Epoch [76/500], Loss: 0.008958, PSNR: 33.60\n",
            "ðŸ”¥ Epoch [77/500], Loss: 0.008872, PSNR: 33.66\n",
            "ðŸ”¥ Epoch [78/500], Loss: 0.008829, PSNR: 33.72\n",
            "ðŸ”¥ Epoch [79/500], Loss: 0.008517, PSNR: 33.87\n",
            "ðŸ”¥ Epoch [80/500], Loss: 0.008148, PSNR: 34.07\n",
            "ðŸ”¥ Epoch [81/500], Loss: 0.007933, PSNR: 34.21\n",
            "ðŸ”¥ Epoch [82/500], Loss: 0.008055, PSNR: 34.12\n",
            "ðŸ”¥ Epoch [83/500], Loss: 0.007565, PSNR: 34.38\n",
            "ðŸ”¥ Epoch [84/500], Loss: 0.007788, PSNR: 34.29\n",
            "ðŸ”¥ Epoch [85/500], Loss: 0.007428, PSNR: 34.50\n",
            "ðŸ”¥ Epoch [86/500], Loss: 0.007443, PSNR: 34.49\n",
            "ðŸ”¥ Epoch [87/500], Loss: 0.007427, PSNR: 34.48\n",
            "ðŸ”¥ Epoch [88/500], Loss: 0.007235, PSNR: 34.65\n",
            "ðŸ”¥ Epoch [89/500], Loss: 0.007486, PSNR: 34.49\n",
            "ðŸ”¥ Epoch [90/500], Loss: 0.007367, PSNR: 34.53\n",
            "ðŸ”¥ Epoch [91/500], Loss: 0.007113, PSNR: 34.72\n",
            "ðŸ”¥ Epoch [92/500], Loss: 0.007273, PSNR: 34.59\n",
            "ðŸ”¥ Epoch [93/500], Loss: 0.007031, PSNR: 34.76\n",
            "ðŸ”¥ Epoch [94/500], Loss: 0.007168, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [95/500], Loss: 0.007180, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [96/500], Loss: 0.007149, PSNR: 34.74\n",
            "ðŸ”¥ Epoch [97/500], Loss: 0.007004, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [98/500], Loss: 0.006897, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [99/500], Loss: 0.007053, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [100/500], Loss: 0.007038, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [101/500], Loss: 0.006945, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [102/500], Loss: 0.007021, PSNR: 34.84\n",
            "ðŸ”¥ Epoch [103/500], Loss: 0.006980, PSNR: 34.84\n",
            "ðŸ”¥ Epoch [104/500], Loss: 0.006913, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [105/500], Loss: 0.006968, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [106/500], Loss: 0.006960, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [107/500], Loss: 0.006959, PSNR: 34.90\n",
            "ðŸ”¥ Epoch [108/500], Loss: 0.006888, PSNR: 34.91\n",
            "ðŸ”¥ Epoch [109/500], Loss: 0.007000, PSNR: 34.86\n",
            "ðŸ”¥ Epoch [110/500], Loss: 0.006841, PSNR: 34.95\n",
            "ðŸ”¥ Epoch [111/500], Loss: 0.006918, PSNR: 34.90\n",
            "ðŸ”¥ Epoch [112/500], Loss: 0.006969, PSNR: 34.90\n",
            "ðŸ”¥ Epoch [113/500], Loss: 0.006959, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [114/500], Loss: 0.007076, PSNR: 34.80\n",
            "ðŸ”¥ Epoch [115/500], Loss: 0.006979, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [116/500], Loss: 0.007071, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [117/500], Loss: 0.006874, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [118/500], Loss: 0.006944, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [119/500], Loss: 0.006938, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [120/500], Loss: 0.006982, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [121/500], Loss: 0.007003, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [122/500], Loss: 0.007002, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [123/500], Loss: 0.007022, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [124/500], Loss: 0.006995, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [125/500], Loss: 0.007007, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [126/500], Loss: 0.007034, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [127/500], Loss: 0.007088, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [128/500], Loss: 0.007055, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [129/500], Loss: 0.007163, PSNR: 34.80\n",
            "ðŸ”¥ Epoch [130/500], Loss: 0.007230, PSNR: 34.74\n",
            "ðŸ”¥ Epoch [131/500], Loss: 0.007080, PSNR: 34.84\n",
            "ðŸ”¥ Epoch [132/500], Loss: 0.007055, PSNR: 34.86\n",
            "ðŸ”¥ Epoch [133/500], Loss: 0.007261, PSNR: 34.73\n",
            "ðŸ”¥ Epoch [134/500], Loss: 0.007203, PSNR: 34.77\n",
            "ðŸ”¥ Epoch [135/500], Loss: 0.007199, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [136/500], Loss: 0.007193, PSNR: 34.80\n",
            "ðŸ”¥ Epoch [137/500], Loss: 0.007186, PSNR: 34.80\n",
            "ðŸ”¥ Epoch [138/500], Loss: 0.007263, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [139/500], Loss: 0.007238, PSNR: 34.77\n",
            "ðŸ”¥ Epoch [140/500], Loss: 0.007269, PSNR: 34.76\n",
            "ðŸ”¥ Epoch [141/500], Loss: 0.007315, PSNR: 34.74\n",
            "ðŸ”¥ Epoch [142/500], Loss: 0.007332, PSNR: 34.77\n",
            "ðŸ”¥ Epoch [143/500], Loss: 0.007315, PSNR: 34.78\n",
            "ðŸ”¥ Epoch [144/500], Loss: 0.007365, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [145/500], Loss: 0.007301, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [146/500], Loss: 0.007124, PSNR: 34.93\n",
            "ðŸ”¥ Epoch [147/500], Loss: 0.007004, PSNR: 34.94\n",
            "ðŸ”¥ Epoch [148/500], Loss: 0.007354, PSNR: 34.74\n",
            "ðŸ”¥ Epoch [149/500], Loss: 0.007326, PSNR: 34.71\n",
            "ðŸ”¥ Epoch [150/500], Loss: 0.007079, PSNR: 34.86\n",
            "ðŸ”¥ Epoch [151/500], Loss: 0.007040, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [152/500], Loss: 0.006994, PSNR: 34.98\n",
            "ðŸ”¥ Epoch [153/500], Loss: 0.007419, PSNR: 34.65\n",
            "ðŸ”¥ Epoch [154/500], Loss: 0.007077, PSNR: 34.86\n",
            "ðŸ”¥ Epoch [155/500], Loss: 0.007230, PSNR: 34.79\n",
            "ðŸ”¥ Epoch [156/500], Loss: 0.007182, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [157/500], Loss: 0.007167, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [158/500], Loss: 0.007253, PSNR: 34.72\n",
            "ðŸ”¥ Epoch [159/500], Loss: 0.007059, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [160/500], Loss: 0.007360, PSNR: 34.67\n",
            "ðŸ”¥ Epoch [161/500], Loss: 0.007258, PSNR: 34.78\n",
            "ðŸ”¥ Epoch [162/500], Loss: 0.007183, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [163/500], Loss: 0.007103, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [164/500], Loss: 0.007192, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [165/500], Loss: 0.007170, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [166/500], Loss: 0.007231, PSNR: 34.86\n",
            "ðŸ”¥ Epoch [167/500], Loss: 0.007529, PSNR: 34.53\n",
            "ðŸ”¥ Epoch [168/500], Loss: 0.007116, PSNR: 34.79\n",
            "ðŸ”¥ Epoch [169/500], Loss: 0.007213, PSNR: 34.76\n",
            "ðŸ”¥ Epoch [170/500], Loss: 0.007294, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [171/500], Loss: 0.007224, PSNR: 34.77\n",
            "ðŸ”¥ Epoch [172/500], Loss: 0.007250, PSNR: 34.69\n",
            "ðŸ”¥ Epoch [173/500], Loss: 0.007219, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [174/500], Loss: 0.007229, PSNR: 34.77\n",
            "ðŸ”¥ Epoch [175/500], Loss: 0.007202, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [176/500], Loss: 0.007358, PSNR: 34.63\n",
            "ðŸ”¥ Epoch [177/500], Loss: 0.007237, PSNR: 34.72\n",
            "ðŸ”¥ Epoch [178/500], Loss: 0.007313, PSNR: 34.70\n",
            "ðŸ”¥ Epoch [179/500], Loss: 0.007625, PSNR: 34.56\n",
            "ðŸ”¥ Epoch [180/500], Loss: 0.007320, PSNR: 34.67\n",
            "ðŸ”¥ Epoch [181/500], Loss: 0.007492, PSNR: 34.61\n",
            "ðŸ”¥ Epoch [182/500], Loss: 0.007290, PSNR: 34.70\n",
            "ðŸ”¥ Epoch [183/500], Loss: 0.007393, PSNR: 34.62\n",
            "ðŸ”¥ Epoch [184/500], Loss: 0.007556, PSNR: 34.58\n",
            "ðŸ”¥ Epoch [185/500], Loss: 0.007540, PSNR: 34.58\n",
            "ðŸ”¥ Epoch [186/500], Loss: 0.007206, PSNR: 34.73\n",
            "ðŸ”¥ Epoch [187/500], Loss: 0.007536, PSNR: 34.56\n",
            "ðŸ”¥ Epoch [188/500], Loss: 0.007453, PSNR: 34.63\n",
            "ðŸ”¥ Epoch [189/500], Loss: 0.007644, PSNR: 34.49\n",
            "ðŸ”¥ Epoch [190/500], Loss: 0.007559, PSNR: 34.50\n",
            "ðŸ”¥ Epoch [191/500], Loss: 0.007719, PSNR: 34.42\n",
            "ðŸ”¥ Epoch [192/500], Loss: 0.007757, PSNR: 34.40\n",
            "ðŸ”¥ Epoch [193/500], Loss: 0.007422, PSNR: 34.68\n",
            "ðŸ”¥ Epoch [194/500], Loss: 0.007781, PSNR: 34.39\n",
            "ðŸ”¥ Epoch [195/500], Loss: 0.007776, PSNR: 34.42\n",
            "ðŸ”¥ Epoch [196/500], Loss: 0.007860, PSNR: 34.36\n",
            "ðŸ”¥ Epoch [197/500], Loss: 0.007668, PSNR: 34.53\n",
            "ðŸ”¥ Epoch [198/500], Loss: 0.007888, PSNR: 34.30\n",
            "ðŸ”¥ Epoch [199/500], Loss: 0.007900, PSNR: 34.28\n",
            "ðŸ”¥ Epoch [200/500], Loss: 0.007657, PSNR: 34.41\n",
            "ðŸ”¥ Epoch [201/500], Loss: 0.007770, PSNR: 34.37\n",
            "ðŸ”¥ Epoch [202/500], Loss: 0.007639, PSNR: 34.47\n",
            "ðŸ”¥ Epoch [203/500], Loss: 0.007845, PSNR: 34.29\n",
            "ðŸ”¥ Epoch [204/500], Loss: 0.008016, PSNR: 34.26\n",
            "ðŸ”¥ Epoch [205/500], Loss: 0.007912, PSNR: 34.30\n",
            "ðŸ”¥ Epoch [206/500], Loss: 0.007916, PSNR: 34.27\n",
            "ðŸ”¥ Epoch [207/500], Loss: 0.007913, PSNR: 34.31\n",
            "ðŸ”¥ Epoch [208/500], Loss: 0.007922, PSNR: 34.29\n",
            "ðŸ”¥ Epoch [209/500], Loss: 0.008049, PSNR: 34.23\n",
            "ðŸ”¥ Epoch [210/500], Loss: 0.008164, PSNR: 34.14\n",
            "ðŸ”¥ Epoch [211/500], Loss: 0.008295, PSNR: 34.07\n",
            "ðŸ”¥ Epoch [212/500], Loss: 0.008549, PSNR: 33.88\n",
            "ðŸ”¥ Epoch [213/500], Loss: 0.008604, PSNR: 33.87\n",
            "ðŸ”¥ Epoch [214/500], Loss: 0.008721, PSNR: 33.80\n",
            "ðŸ”¥ Epoch [215/500], Loss: 0.008580, PSNR: 33.88\n",
            "ðŸ”¥ Epoch [216/500], Loss: 0.008944, PSNR: 33.72\n",
            "ðŸ”¥ Epoch [217/500], Loss: 0.008853, PSNR: 33.76\n",
            "ðŸ”¥ Epoch [218/500], Loss: 0.008666, PSNR: 33.84\n",
            "ðŸ”¥ Epoch [219/500], Loss: 0.009015, PSNR: 33.70\n",
            "ðŸ”¥ Epoch [220/500], Loss: 0.009053, PSNR: 33.63\n",
            "ðŸ”¥ Epoch [221/500], Loss: 0.008818, PSNR: 33.77\n",
            "ðŸ”¥ Epoch [222/500], Loss: 0.008930, PSNR: 33.73\n",
            "ðŸ”¥ Epoch [223/500], Loss: 0.008937, PSNR: 33.72\n",
            "ðŸ”¥ Epoch [224/500], Loss: 0.009151, PSNR: 33.58\n",
            "ðŸ”¥ Epoch [225/500], Loss: 0.009028, PSNR: 33.65\n",
            "ðŸ”¥ Epoch [226/500], Loss: 0.009020, PSNR: 33.66\n",
            "ðŸ”¥ Epoch [227/500], Loss: 0.009092, PSNR: 33.60\n",
            "ðŸ”¥ Epoch [228/500], Loss: 0.009369, PSNR: 33.42\n",
            "ðŸ”¥ Epoch [229/500], Loss: 0.009197, PSNR: 33.54\n",
            "ðŸ”¥ Epoch [230/500], Loss: 0.009907, PSNR: 33.25\n",
            "ðŸ”¥ Epoch [231/500], Loss: 0.010204, PSNR: 33.07\n",
            "ðŸ”¥ Epoch [232/500], Loss: 0.010202, PSNR: 33.10\n",
            "ðŸ”¥ Epoch [233/500], Loss: 0.010818, PSNR: 32.82\n",
            "ðŸ”¥ Epoch [234/500], Loss: 0.010538, PSNR: 32.88\n",
            "ðŸ”¥ Epoch [235/500], Loss: 0.010872, PSNR: 32.72\n",
            "ðŸ”¥ Epoch [236/500], Loss: 0.011656, PSNR: 32.48\n",
            "ðŸ”¥ Epoch [237/500], Loss: 0.012333, PSNR: 32.23\n",
            "ðŸ”¥ Epoch [238/500], Loss: 0.012658, PSNR: 32.09\n",
            "ðŸ”¥ Epoch [239/500], Loss: 0.013015, PSNR: 31.93\n",
            "ðŸ”¥ Epoch [240/500], Loss: 0.012957, PSNR: 31.88\n",
            "ðŸ”¥ Epoch [241/500], Loss: 0.013759, PSNR: 31.65\n",
            "ðŸ”¥ Epoch [242/500], Loss: 0.014219, PSNR: 31.51\n",
            "ðŸ”¥ Epoch [243/500], Loss: 0.014891, PSNR: 31.32\n",
            "ðŸ”¥ Epoch [244/500], Loss: 0.015502, PSNR: 31.15\n",
            "ðŸ”¥ Epoch [245/500], Loss: 0.016561, PSNR: 30.80\n",
            "ðŸ”¥ Epoch [246/500], Loss: 0.018314, PSNR: 30.36\n",
            "ðŸ”¥ Epoch [247/500], Loss: 0.018977, PSNR: 30.16\n",
            "ðŸ”¥ Epoch [248/500], Loss: 0.022042, PSNR: 29.51\n",
            "ðŸ”¥ Epoch [249/500], Loss: 0.025455, PSNR: 28.88\n",
            "ðŸ”¥ Epoch [250/500], Loss: 0.029221, PSNR: 28.24\n",
            "ðŸ”¥ Epoch [251/500], Loss: 0.038676, PSNR: 27.06\n",
            "ðŸ”¥ Epoch [252/500], Loss: 0.061063, PSNR: 25.07\n",
            "ðŸ”¥ Epoch [253/500], Loss: 0.120003, PSNR: 22.24\n",
            "ðŸ”¥ Epoch [254/500], Loss: 0.326394, PSNR: 17.95\n",
            "ðŸ”¥ Epoch [255/500], Loss: 1.558237, PSNR: 11.55\n",
            "ðŸ”¥ Epoch [256/500], Loss: 3.655735, PSNR: 7.32\n",
            "ðŸ”¥ Epoch [257/500], Loss: 5.943572, PSNR: 5.20\n",
            "ðŸ”¥ Epoch [258/500], Loss: 9.709883, PSNR: 3.02\n",
            "ðŸ”¥ Epoch [259/500], Loss: 10.717449, PSNR: 2.58\n",
            "ðŸ”¥ Epoch [260/500], Loss: 8.718062, PSNR: 3.47\n",
            "ðŸ”¥ Epoch [261/500], Loss: 6.913086, PSNR: 4.47\n",
            "ðŸ”¥ Epoch [262/500], Loss: 6.156909, PSNR: 4.98\n",
            "ðŸ”¥ Epoch [263/500], Loss: 5.322130, PSNR: 5.61\n",
            "ðŸ”¥ Epoch [264/500], Loss: 4.627240, PSNR: 6.21\n",
            "ðŸ”¥ Epoch [265/500], Loss: 4.194437, PSNR: 6.64\n",
            "ðŸ”¥ Epoch [266/500], Loss: 3.756084, PSNR: 7.12\n",
            "ðŸ”¥ Epoch [267/500], Loss: 3.375067, PSNR: 7.58\n",
            "ðŸ”¥ Epoch [268/500], Loss: 3.129258, PSNR: 7.91\n",
            "ðŸ”¥ Epoch [269/500], Loss: 2.852199, PSNR: 8.32\n",
            "ðŸ”¥ Epoch [270/500], Loss: 2.612535, PSNR: 8.70\n",
            "ðŸ”¥ Epoch [271/500], Loss: 2.377193, PSNR: 9.11\n",
            "ðŸ”¥ Epoch [272/500], Loss: 2.196763, PSNR: 9.45\n",
            "ðŸ”¥ Epoch [273/500], Loss: 2.006211, PSNR: 9.85\n",
            "ðŸ”¥ Epoch [274/500], Loss: 1.833404, PSNR: 10.24\n",
            "ðŸ”¥ Epoch [275/500], Loss: 1.696135, PSNR: 10.58\n",
            "ðŸ”¥ Epoch [276/500], Loss: 1.566038, PSNR: 10.92\n",
            "ðŸ”¥ Epoch [277/500], Loss: 1.427234, PSNR: 11.33\n",
            "ðŸ”¥ Epoch [278/500], Loss: 1.325428, PSNR: 11.65\n",
            "ðŸ”¥ Epoch [279/500], Loss: 1.208098, PSNR: 12.05\n",
            "ðŸ”¥ Epoch [280/500], Loss: 1.126752, PSNR: 12.36\n",
            "ðŸ”¥ Epoch [281/500], Loss: 1.035925, PSNR: 12.72\n",
            "ðŸ”¥ Epoch [282/500], Loss: 0.948506, PSNR: 13.10\n",
            "ðŸ”¥ Epoch [283/500], Loss: 0.866846, PSNR: 13.50\n",
            "ðŸ”¥ Epoch [284/500], Loss: 0.795051, PSNR: 13.87\n",
            "ðŸ”¥ Epoch [285/500], Loss: 0.743429, PSNR: 14.17\n",
            "ðŸ”¥ Epoch [286/500], Loss: 0.686053, PSNR: 14.52\n",
            "ðŸ”¥ Epoch [287/500], Loss: 0.624734, PSNR: 14.93\n",
            "ðŸ”¥ Epoch [288/500], Loss: 0.568939, PSNR: 15.33\n",
            "ðŸ”¥ Epoch [289/500], Loss: 0.528708, PSNR: 15.66\n",
            "ðŸ”¥ Epoch [290/500], Loss: 0.485238, PSNR: 16.03\n",
            "ðŸ”¥ Epoch [291/500], Loss: 0.441335, PSNR: 16.45\n",
            "ðŸ”¥ Epoch [292/500], Loss: 0.410172, PSNR: 16.76\n",
            "ðŸ”¥ Epoch [293/500], Loss: 0.375153, PSNR: 17.15\n",
            "ðŸ”¥ Epoch [294/500], Loss: 0.342818, PSNR: 17.54\n",
            "ðŸ”¥ Epoch [295/500], Loss: 0.310156, PSNR: 17.98\n",
            "ðŸ”¥ Epoch [296/500], Loss: 0.291620, PSNR: 18.26\n",
            "ðŸ”¥ Epoch [297/500], Loss: 0.260287, PSNR: 18.76\n",
            "ðŸ”¥ Epoch [298/500], Loss: 0.242195, PSNR: 19.08\n",
            "ðŸ”¥ Epoch [299/500], Loss: 0.221049, PSNR: 19.47\n",
            "ðŸ”¥ Epoch [300/500], Loss: 0.201711, PSNR: 19.89\n",
            "ðŸ”¥ Epoch [301/500], Loss: 0.184467, PSNR: 20.27\n",
            "ðŸ”¥ Epoch [302/500], Loss: 0.166970, PSNR: 20.71\n",
            "ðŸ”¥ Epoch [303/500], Loss: 0.153066, PSNR: 21.10\n",
            "ðŸ”¥ Epoch [304/500], Loss: 0.139779, PSNR: 21.50\n",
            "ðŸ”¥ Epoch [305/500], Loss: 0.127147, PSNR: 21.93\n",
            "ðŸ”¥ Epoch [306/500], Loss: 0.116081, PSNR: 22.33\n",
            "ðŸ”¥ Epoch [307/500], Loss: 0.106285, PSNR: 22.71\n",
            "ðŸ”¥ Epoch [308/500], Loss: 0.095676, PSNR: 23.19\n",
            "ðŸ”¥ Epoch [309/500], Loss: 0.088072, PSNR: 23.55\n",
            "ðŸ”¥ Epoch [310/500], Loss: 0.079413, PSNR: 24.02\n",
            "ðŸ”¥ Epoch [311/500], Loss: 0.072894, PSNR: 24.39\n",
            "ðŸ”¥ Epoch [312/500], Loss: 0.066524, PSNR: 24.80\n",
            "ðŸ”¥ Epoch [313/500], Loss: 0.060771, PSNR: 25.22\n",
            "ðŸ”¥ Epoch [314/500], Loss: 0.054871, PSNR: 25.67\n",
            "ðŸ”¥ Epoch [315/500], Loss: 0.050252, PSNR: 26.09\n",
            "ðŸ”¥ Epoch [316/500], Loss: 0.045896, PSNR: 26.48\n",
            "ðŸ”¥ Epoch [317/500], Loss: 0.041869, PSNR: 26.88\n",
            "ðŸ”¥ Epoch [318/500], Loss: 0.037792, PSNR: 27.36\n",
            "ðŸ”¥ Epoch [319/500], Loss: 0.034695, PSNR: 27.77\n",
            "ðŸ”¥ Epoch [320/500], Loss: 0.031621, PSNR: 28.17\n",
            "ðŸ”¥ Epoch [321/500], Loss: 0.028842, PSNR: 28.58\n",
            "ðŸ”¥ Epoch [322/500], Loss: 0.026397, PSNR: 28.97\n",
            "ðŸ”¥ Epoch [323/500], Loss: 0.024385, PSNR: 29.33\n",
            "ðŸ”¥ Epoch [324/500], Loss: 0.022075, PSNR: 29.78\n",
            "ðŸ”¥ Epoch [325/500], Loss: 0.020577, PSNR: 30.09\n",
            "ðŸ”¥ Epoch [326/500], Loss: 0.018697, PSNR: 30.50\n",
            "ðŸ”¥ Epoch [327/500], Loss: 0.017706, PSNR: 30.73\n",
            "ðŸ”¥ Epoch [328/500], Loss: 0.016087, PSNR: 31.17\n",
            "ðŸ”¥ Epoch [329/500], Loss: 0.015018, PSNR: 31.47\n",
            "ðŸ”¥ Epoch [330/500], Loss: 0.013994, PSNR: 31.75\n",
            "ðŸ”¥ Epoch [331/500], Loss: 0.013077, PSNR: 32.07\n",
            "ðŸ”¥ Epoch [332/500], Loss: 0.012174, PSNR: 32.36\n",
            "ðŸ”¥ Epoch [333/500], Loss: 0.011487, PSNR: 32.62\n",
            "ðŸ”¥ Epoch [334/500], Loss: 0.010794, PSNR: 32.85\n",
            "ðŸ”¥ Epoch [335/500], Loss: 0.010319, PSNR: 33.05\n",
            "ðŸ”¥ Epoch [336/500], Loss: 0.009869, PSNR: 33.24\n",
            "ðŸ”¥ Epoch [337/500], Loss: 0.009246, PSNR: 33.51\n",
            "ðŸ”¥ Epoch [338/500], Loss: 0.008852, PSNR: 33.70\n",
            "ðŸ”¥ Epoch [339/500], Loss: 0.008600, PSNR: 33.80\n",
            "ðŸ”¥ Epoch [340/500], Loss: 0.008263, PSNR: 34.00\n",
            "ðŸ”¥ Epoch [341/500], Loss: 0.007886, PSNR: 34.17\n",
            "ðŸ”¥ Epoch [342/500], Loss: 0.007768, PSNR: 34.26\n",
            "ðŸ”¥ Epoch [343/500], Loss: 0.007465, PSNR: 34.39\n",
            "ðŸ”¥ Epoch [344/500], Loss: 0.007366, PSNR: 34.48\n",
            "ðŸ”¥ Epoch [345/500], Loss: 0.007225, PSNR: 34.56\n",
            "ðŸ”¥ Epoch [346/500], Loss: 0.007052, PSNR: 34.68\n",
            "ðŸ”¥ Epoch [347/500], Loss: 0.006913, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [348/500], Loss: 0.006842, PSNR: 34.79\n",
            "ðŸ”¥ Epoch [349/500], Loss: 0.006726, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [350/500], Loss: 0.006571, PSNR: 34.97\n",
            "ðŸ”¥ Epoch [351/500], Loss: 0.006515, PSNR: 35.01\n",
            "ðŸ”¥ Epoch [352/500], Loss: 0.006538, PSNR: 35.02\n",
            "ðŸ”¥ Epoch [353/500], Loss: 0.006438, PSNR: 35.09\n",
            "ðŸ”¥ Epoch [354/500], Loss: 0.006366, PSNR: 35.16\n",
            "ðŸ”¥ Epoch [355/500], Loss: 0.006439, PSNR: 35.10\n",
            "ðŸ”¥ Epoch [356/500], Loss: 0.006349, PSNR: 35.14\n",
            "ðŸ”¥ Epoch [357/500], Loss: 0.006291, PSNR: 35.20\n",
            "ðŸ”¥ Epoch [358/500], Loss: 0.006255, PSNR: 35.25\n",
            "ðŸ”¥ Epoch [359/500], Loss: 0.006301, PSNR: 35.20\n",
            "ðŸ”¥ Epoch [360/500], Loss: 0.006197, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [361/500], Loss: 0.006260, PSNR: 35.26\n",
            "ðŸ”¥ Epoch [362/500], Loss: 0.006279, PSNR: 35.26\n",
            "ðŸ”¥ Epoch [363/500], Loss: 0.006231, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [364/500], Loss: 0.006259, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [365/500], Loss: 0.006237, PSNR: 35.33\n",
            "ðŸ”¥ Epoch [366/500], Loss: 0.006276, PSNR: 35.27\n",
            "ðŸ”¥ Epoch [367/500], Loss: 0.006255, PSNR: 35.31\n",
            "ðŸ”¥ Epoch [368/500], Loss: 0.006284, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [369/500], Loss: 0.006210, PSNR: 35.35\n",
            "ðŸ”¥ Epoch [370/500], Loss: 0.006166, PSNR: 35.38\n",
            "ðŸ”¥ Epoch [371/500], Loss: 0.006232, PSNR: 35.32\n",
            "ðŸ”¥ Epoch [372/500], Loss: 0.006235, PSNR: 35.34\n",
            "ðŸ”¥ Epoch [373/500], Loss: 0.006222, PSNR: 35.33\n",
            "ðŸ”¥ Epoch [374/500], Loss: 0.006199, PSNR: 35.37\n",
            "ðŸ”¥ Epoch [375/500], Loss: 0.006285, PSNR: 35.31\n",
            "ðŸ”¥ Epoch [376/500], Loss: 0.006204, PSNR: 35.33\n",
            "ðŸ”¥ Epoch [377/500], Loss: 0.006177, PSNR: 35.38\n",
            "ðŸ”¥ Epoch [378/500], Loss: 0.006249, PSNR: 35.33\n",
            "ðŸ”¥ Epoch [379/500], Loss: 0.006238, PSNR: 35.32\n",
            "ðŸ”¥ Epoch [380/500], Loss: 0.006259, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [381/500], Loss: 0.006297, PSNR: 35.34\n",
            "ðŸ”¥ Epoch [382/500], Loss: 0.006210, PSNR: 35.38\n",
            "ðŸ”¥ Epoch [383/500], Loss: 0.006222, PSNR: 35.35\n",
            "ðŸ”¥ Epoch [384/500], Loss: 0.006281, PSNR: 35.35\n",
            "ðŸ”¥ Epoch [385/500], Loss: 0.006235, PSNR: 35.32\n",
            "ðŸ”¥ Epoch [386/500], Loss: 0.006277, PSNR: 35.32\n",
            "ðŸ”¥ Epoch [387/500], Loss: 0.006234, PSNR: 35.35\n",
            "ðŸ”¥ Epoch [388/500], Loss: 0.006231, PSNR: 35.37\n",
            "ðŸ”¥ Epoch [389/500], Loss: 0.006255, PSNR: 35.36\n",
            "ðŸ”¥ Epoch [390/500], Loss: 0.006314, PSNR: 35.28\n",
            "ðŸ”¥ Epoch [391/500], Loss: 0.006275, PSNR: 35.36\n",
            "ðŸ”¥ Epoch [392/500], Loss: 0.006365, PSNR: 35.28\n",
            "ðŸ”¥ Epoch [393/500], Loss: 0.006230, PSNR: 35.39\n",
            "ðŸ”¥ Epoch [394/500], Loss: 0.006169, PSNR: 35.37\n",
            "ðŸ”¥ Epoch [395/500], Loss: 0.006348, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [396/500], Loss: 0.006290, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [397/500], Loss: 0.006257, PSNR: 35.34\n",
            "ðŸ”¥ Epoch [398/500], Loss: 0.006348, PSNR: 35.27\n",
            "ðŸ”¥ Epoch [399/500], Loss: 0.006293, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [400/500], Loss: 0.006331, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [401/500], Loss: 0.006322, PSNR: 35.31\n",
            "ðŸ”¥ Epoch [402/500], Loss: 0.006346, PSNR: 35.24\n",
            "ðŸ”¥ Epoch [403/500], Loss: 0.006273, PSNR: 35.33\n",
            "ðŸ”¥ Epoch [404/500], Loss: 0.006387, PSNR: 35.25\n",
            "ðŸ”¥ Epoch [405/500], Loss: 0.006328, PSNR: 35.27\n",
            "ðŸ”¥ Epoch [406/500], Loss: 0.006306, PSNR: 35.29\n",
            "ðŸ”¥ Epoch [407/500], Loss: 0.006294, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [408/500], Loss: 0.006304, PSNR: 35.28\n",
            "ðŸ”¥ Epoch [409/500], Loss: 0.006466, PSNR: 35.21\n",
            "ðŸ”¥ Epoch [410/500], Loss: 0.006350, PSNR: 35.28\n",
            "ðŸ”¥ Epoch [411/500], Loss: 0.006404, PSNR: 35.27\n",
            "ðŸ”¥ Epoch [412/500], Loss: 0.006285, PSNR: 35.30\n",
            "ðŸ”¥ Epoch [413/500], Loss: 0.006363, PSNR: 35.25\n",
            "ðŸ”¥ Epoch [414/500], Loss: 0.006460, PSNR: 35.18\n",
            "ðŸ”¥ Epoch [415/500], Loss: 0.006480, PSNR: 35.13\n",
            "ðŸ”¥ Epoch [416/500], Loss: 0.006403, PSNR: 35.24\n",
            "ðŸ”¥ Epoch [417/500], Loss: 0.006332, PSNR: 35.25\n",
            "ðŸ”¥ Epoch [418/500], Loss: 0.006490, PSNR: 35.19\n",
            "ðŸ”¥ Epoch [419/500], Loss: 0.006369, PSNR: 35.25\n",
            "ðŸ”¥ Epoch [420/500], Loss: 0.006476, PSNR: 35.17\n",
            "ðŸ”¥ Epoch [421/500], Loss: 0.006481, PSNR: 35.17\n",
            "ðŸ”¥ Epoch [422/500], Loss: 0.006321, PSNR: 35.31\n",
            "ðŸ”¥ Epoch [423/500], Loss: 0.006526, PSNR: 35.13\n",
            "ðŸ”¥ Epoch [424/500], Loss: 0.006490, PSNR: 35.17\n",
            "ðŸ”¥ Epoch [425/500], Loss: 0.006373, PSNR: 35.24\n",
            "ðŸ”¥ Epoch [426/500], Loss: 0.006507, PSNR: 35.14\n",
            "ðŸ”¥ Epoch [427/500], Loss: 0.006402, PSNR: 35.21\n",
            "ðŸ”¥ Epoch [428/500], Loss: 0.006434, PSNR: 35.22\n",
            "ðŸ”¥ Epoch [429/500], Loss: 0.006379, PSNR: 35.22\n",
            "ðŸ”¥ Epoch [430/500], Loss: 0.006436, PSNR: 35.20\n",
            "ðŸ”¥ Epoch [431/500], Loss: 0.006576, PSNR: 35.06\n",
            "ðŸ”¥ Epoch [432/500], Loss: 0.006549, PSNR: 35.08\n",
            "ðŸ”¥ Epoch [433/500], Loss: 0.006552, PSNR: 35.13\n",
            "ðŸ”¥ Epoch [434/500], Loss: 0.006403, PSNR: 35.22\n",
            "ðŸ”¥ Epoch [435/500], Loss: 0.006611, PSNR: 35.08\n",
            "ðŸ”¥ Epoch [436/500], Loss: 0.006496, PSNR: 35.15\n",
            "ðŸ”¥ Epoch [437/500], Loss: 0.006530, PSNR: 35.11\n",
            "ðŸ”¥ Epoch [438/500], Loss: 0.006551, PSNR: 35.09\n",
            "ðŸ”¥ Epoch [439/500], Loss: 0.006548, PSNR: 35.14\n",
            "ðŸ”¥ Epoch [440/500], Loss: 0.006580, PSNR: 35.08\n",
            "ðŸ”¥ Epoch [441/500], Loss: 0.006518, PSNR: 35.11\n",
            "ðŸ”¥ Epoch [442/500], Loss: 0.006602, PSNR: 35.04\n",
            "ðŸ”¥ Epoch [443/500], Loss: 0.006647, PSNR: 35.07\n",
            "ðŸ”¥ Epoch [444/500], Loss: 0.006539, PSNR: 35.12\n",
            "ðŸ”¥ Epoch [445/500], Loss: 0.006633, PSNR: 35.06\n",
            "ðŸ”¥ Epoch [446/500], Loss: 0.006605, PSNR: 35.07\n",
            "ðŸ”¥ Epoch [447/500], Loss: 0.006628, PSNR: 35.03\n",
            "ðŸ”¥ Epoch [448/500], Loss: 0.006617, PSNR: 35.06\n",
            "ðŸ”¥ Epoch [449/500], Loss: 0.006626, PSNR: 35.07\n",
            "ðŸ”¥ Epoch [450/500], Loss: 0.006612, PSNR: 35.05\n",
            "ðŸ”¥ Epoch [451/500], Loss: 0.006590, PSNR: 35.04\n",
            "ðŸ”¥ Epoch [452/500], Loss: 0.006705, PSNR: 34.99\n",
            "ðŸ”¥ Epoch [453/500], Loss: 0.006645, PSNR: 35.02\n",
            "ðŸ”¥ Epoch [454/500], Loss: 0.006666, PSNR: 35.05\n",
            "ðŸ”¥ Epoch [455/500], Loss: 0.006554, PSNR: 35.10\n",
            "ðŸ”¥ Epoch [456/500], Loss: 0.006624, PSNR: 35.03\n",
            "ðŸ”¥ Epoch [457/500], Loss: 0.006647, PSNR: 35.01\n",
            "ðŸ”¥ Epoch [458/500], Loss: 0.006640, PSNR: 35.03\n",
            "ðŸ”¥ Epoch [459/500], Loss: 0.006638, PSNR: 35.00\n",
            "ðŸ”¥ Epoch [460/500], Loss: 0.006625, PSNR: 35.04\n",
            "ðŸ”¥ Epoch [461/500], Loss: 0.006829, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [462/500], Loss: 0.006711, PSNR: 35.00\n",
            "ðŸ”¥ Epoch [463/500], Loss: 0.006551, PSNR: 35.09\n",
            "ðŸ”¥ Epoch [464/500], Loss: 0.006752, PSNR: 34.95\n",
            "ðŸ”¥ Epoch [465/500], Loss: 0.006768, PSNR: 34.99\n",
            "ðŸ”¥ Epoch [466/500], Loss: 0.006824, PSNR: 34.94\n",
            "ðŸ”¥ Epoch [467/500], Loss: 0.006813, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [468/500], Loss: 0.006795, PSNR: 34.95\n",
            "ðŸ”¥ Epoch [469/500], Loss: 0.006872, PSNR: 34.91\n",
            "ðŸ”¥ Epoch [470/500], Loss: 0.006803, PSNR: 34.91\n",
            "ðŸ”¥ Epoch [471/500], Loss: 0.006796, PSNR: 34.93\n",
            "ðŸ”¥ Epoch [472/500], Loss: 0.006833, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [473/500], Loss: 0.006812, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [474/500], Loss: 0.006802, PSNR: 34.90\n",
            "ðŸ”¥ Epoch [475/500], Loss: 0.006740, PSNR: 35.01\n",
            "ðŸ”¥ Epoch [476/500], Loss: 0.006913, PSNR: 34.81\n",
            "ðŸ”¥ Epoch [477/500], Loss: 0.006826, PSNR: 34.92\n",
            "ðŸ”¥ Epoch [478/500], Loss: 0.006866, PSNR: 34.89\n",
            "ðŸ”¥ Epoch [479/500], Loss: 0.006821, PSNR: 34.94\n",
            "ðŸ”¥ Epoch [480/500], Loss: 0.006867, PSNR: 34.88\n",
            "ðŸ”¥ Epoch [481/500], Loss: 0.006890, PSNR: 34.85\n",
            "ðŸ”¥ Epoch [482/500], Loss: 0.006895, PSNR: 34.85\n",
            "ðŸ”¥ Epoch [483/500], Loss: 0.007007, PSNR: 34.72\n",
            "ðŸ”¥ Epoch [484/500], Loss: 0.006999, PSNR: 34.79\n",
            "ðŸ”¥ Epoch [485/500], Loss: 0.007032, PSNR: 34.76\n",
            "ðŸ”¥ Epoch [486/500], Loss: 0.006905, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [487/500], Loss: 0.006944, PSNR: 34.80\n",
            "ðŸ”¥ Epoch [488/500], Loss: 0.007060, PSNR: 34.73\n",
            "ðŸ”¥ Epoch [489/500], Loss: 0.006870, PSNR: 34.87\n",
            "ðŸ”¥ Epoch [490/500], Loss: 0.006929, PSNR: 34.79\n",
            "ðŸ”¥ Epoch [491/500], Loss: 0.006926, PSNR: 34.83\n",
            "ðŸ”¥ Epoch [492/500], Loss: 0.007014, PSNR: 34.72\n",
            "ðŸ”¥ Epoch [493/500], Loss: 0.007036, PSNR: 34.75\n",
            "ðŸ”¥ Epoch [494/500], Loss: 0.007140, PSNR: 34.68\n",
            "ðŸ”¥ Epoch [495/500], Loss: 0.007079, PSNR: 34.69\n",
            "ðŸ”¥ Epoch [496/500], Loss: 0.007159, PSNR: 34.65\n",
            "ðŸ”¥ Epoch [497/500], Loss: 0.007100, PSNR: 34.69\n",
            "ðŸ”¥ Epoch [498/500], Loss: 0.007193, PSNR: 34.63\n",
            "ðŸ”¥ Epoch [499/500], Loss: 0.007155, PSNR: 34.73\n",
            "ðŸ”¥ Epoch [500/500], Loss: 0.007017, PSNR: 34.77\n"
          ]
        }
      ]
    }
  ]
}